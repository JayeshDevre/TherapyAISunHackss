# ğŸ§  Therapy AI â€” Enterprise-Grade AI Training Platform

> **A production-ready, full-stack AI application for therapy training with dual LLM support, real-time WebSocket communication, and advanced security features.**

[![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=flat&logo=typescript&logoColor=white)](https://www.typescriptlang.org/)
[![Next.js](https://img.shields.io/badge/Next.js-15-black?style=flat&logo=next.js&logoColor=white)](https://nextjs.org/)
[![Node.js](https://img.shields.io/badge/Node.js-20-green?style=flat&logo=node.js&logoColor=white)](https://nodejs.org/)
[![Express](https://img.shields.io/badge/Express-4.x-gray?style=flat&logo=express&logoColor=white)](https://expressjs.com/)

---

## ğŸ¯ Project Overview

**Therapy AI** is a sophisticated, production-ready platform that enables medical students and practitioners to practice therapeutic skills with AI-powered personas. Built with enterprise-grade architecture, it demonstrates advanced full-stack development, real-time systems, AI/ML integration, and security best practices.

### Key Highlights

- âœ… **Production-Ready**: SQLite persistence, rate limiting, security headers, structured logging
- âœ… **Dual LLM Architecture**: Seamless switching between Google Gemini (cloud) and Ollama (local)
- âœ… **Real-Time Communication**: WebSocket-based bidirectional chat with session management
- âœ… **AI Persona Generation**: Upload therapy case documents (PDF/DOCX) to generate custom AI personas
- âœ… **Enterprise Security**: Input validation, sanitization, rate limiting, helmet.js protection
- âœ… **Scalable Architecture**: Modular service design with fallback mechanisms

---

## ğŸš€ Technical Achievements

### Production-Ready Features

| Feature | Implementation | Impact |
|---------|---------------|--------|
| **Persistent Storage** | SQLite with ACID transactions | Zero data loss on server restarts |
| **Rate Limiting** | 100 req/15min per IP with express-rate-limit | DDoS protection, abuse prevention |
| **Security Headers** | Helmet.js (XSS, CSRF, clickjacking protection) | Enterprise-grade security |
| **Structured Logging** | JSON-formatted logs with levels (info/warn/error) | Production monitoring & debugging |
| **Input Validation** | Middleware-based sanitization & validation | Injection attack prevention |
| **Error Handling** | Comprehensive error boundaries with user-friendly messages | Improved UX & reliability |

### Architecture Highlights

- **Dual LLM Provider System**: Abstracted provider pattern allowing runtime switching between cloud (Gemini) and local (Ollama) LLMs
- **WebSocket Real-Time Engine**: Persistent connections with keep-alive, session management, and graceful error handling
- **Document Processing Pipeline**: Multi-format support (PDF/DOCX) with AI-powered persona extraction
- **Modular Service Architecture**: Interface-based design with fallback chains (SQLite â†’ GCS â†’ In-Memory)
- **Type-Safe Development**: Full TypeScript coverage across frontend and backend

---

## ğŸ—ï¸ Technology Stack

### Frontend
- **Next.js 15** with App Router - Modern React framework with server-side rendering
- **React 18** - Component-based UI with hooks and context
- **TypeScript** - Type-safe development with strict mode
- **Tailwind CSS** - Utility-first responsive design
- **WebSocket API** - Real-time bidirectional communication
- **SpeechSynthesis API** - Browser-based text-to-speech

### Backend
- **Node.js 20** - JavaScript runtime
- **Express.js** - RESTful API framework
- **TypeScript** - Full type safety
- **WebSocket (ws)** - Real-time WebSocket server
- **SQLite (better-sqlite3)** - Persistent database with ACID transactions
- **Helmet.js** - Security headers middleware
- **express-rate-limit** - API rate limiting
- **Multer** - File upload handling
- **Mammoth** - DOCX document parsing
- **pdf-parse** - PDF text extraction

### AI & ML
- **Google Gemini 2.5 Flash** - Cloud-based LLM via API
- **Ollama (Llama 3)** - Local LLM for privacy-focused deployments
- **Custom Persona Generation** - AI-powered extraction from therapy case documents

### Infrastructure
- **Docker** - Containerization support
- **Vercel** - Frontend deployment ready
- **Railway** - Backend deployment ready
- **Environment-based Configuration** - Secure secrets management

---

## ğŸ“ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CLIENT LAYER (Frontend)                              â”‚
â”‚                                                                             â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚     â”‚   Next.js 15    â”‚    â”‚   WebSocket     â”‚    â”‚   React 18      â”‚       â”‚
â”‚     â”‚   App Router    â”‚â—„â”€â”€â”€â”¤   Client        â”‚    â”‚   Components    â”‚       â”‚
â”‚     â”‚  (Port 3000)    â”‚    â”‚  (Real-time)    â”‚    â”‚   + Hooks       â”‚       â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚              â”‚                      â”‚                                       â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                     â”‚
          HTTP/REST (Port 3001)    WebSocket (Port 8080)
                    â”‚                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      APPLICATION LAYER (Backend)                          â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Express    â”‚  â”‚  WebSocket   â”‚  â”‚   Auth       â”‚  â”‚  Middleware  â”‚   â”‚
â”‚  â”‚   REST API   â”‚  â”‚   Server     â”‚  â”‚   Service    â”‚  â”‚              â”‚   â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚  â”‚ Rate Limit   â”‚   â”‚
â”‚  â”‚ â€¢ Auth       â”‚  â”‚ â€¢ Sessions   â”‚  â”‚ â€¢ SQLite     â”‚  â”‚ Validation   â”‚   â”‚
â”‚  â”‚ â€¢ Personas   â”‚  â”‚ â€¢ Real-time  â”‚  â”‚ â€¢ GCS        â”‚  â”‚ Logging      â”‚   â”‚
â”‚  â”‚ â€¢ Health     â”‚  â”‚ â€¢ Keep-alive â”‚  â”‚ â€¢ Fallback   â”‚  â”‚              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”˜
          â”‚                  â”‚                â”‚
          â”‚                  â”‚                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           SERVICE LAYER                                    â”‚
â”‚                                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   LLM        â”‚  â”‚   SQLite     â”‚  â”‚   Document   â”‚  â”‚   Persona    â”‚    â”‚
â”‚  â”‚   Router     â”‚  â”‚   Database   â”‚  â”‚   Parser     â”‚  â”‚   Generator  â”‚    â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚    â”‚
â”‚  â”‚ â€¢ Gemini     â”‚  â”‚ â€¢ ACID       â”‚  â”‚ â€¢ PDF Parse  â”‚  â”‚ â€¢ AI Extract â”‚    â”‚
â”‚  â”‚ â€¢ Ollama     â”‚  â”‚ â€¢ Indexed    â”‚  â”‚ â€¢ DOCX Parse â”‚  â”‚ â€¢ Few-shot   â”‚    â”‚
â”‚  â”‚ â€¢ Lazy Init  â”‚  â”‚ â€¢ Persistent â”‚  â”‚ â€¢ Validation â”‚  â”‚ â€¢ JSON Store â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        EXTERNAL SERVICES                                    â”‚
â”‚                                                                             â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚     â”‚  Google Gemini API   â”‚          â”‚   Ollama (Local)     â”‚              â”‚
â”‚     â”‚                      â”‚          â”‚                      â”‚              â”‚
â”‚     â”‚ â€¢ Gemini 2.5 Flash   â”‚          â”‚ â€¢ Llama 3 Model      â”‚              â”‚
â”‚     â”‚ â€¢ Cloud-based        â”‚          â”‚ â€¢ Local Inference    â”‚              â”‚
â”‚     â”‚ â€¢ API Key Required   â”‚          â”‚ â€¢ Privacy-focused    â”‚              â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

```
User Input
    â”‚
    â”œâ”€â–º WebSocket â”€â”€â–º Server â”€â”€â–º Crisis Detection
    â”‚                              â”‚
    â”‚                              â”œâ”€â–º [Crisis] â”€â”€â–º Safety Response
    â”‚                              â”‚
    â”‚                              â””â”€â–º [Normal] â”€â”€â–º Persona Loader
    â”‚                                                    â”‚
    â”‚                                                    â”œâ”€â–º System Prompt
    â”‚                                                    â”œâ”€â–º Few-shot Examples
    â”‚                                                    â””â”€â–º Conversation History
    â”‚                                                          â”‚
    â”‚                                                          â–¼
    â”‚                                                    LLM Router
    â”‚                                                          â”‚
    â”‚                                                          â”œâ”€â–º Gemini API
    â”‚                                                          â”‚   (Cloud)
    â”‚                                                          â”‚
    â”‚                                                          â””â”€â–º Ollama HTTP
    â”‚                                                              (Local)
    â”‚                                                          â”‚
    â”‚                                                          â–¼
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ AI Response
                                                              â”‚
                                                              â–¼
                                                    WebSocket â”€â”€â–º Frontend
                                                              â”‚
                                                              â”œâ”€â–º UI Display
                                                              â””â”€â–º Speech Synthesis
```

### Component Architecture

**Frontend (Next.js)**
- `TherapyAi.tsx` - Main therapy interface with WebSocket client, session management, and real-time chat
- `PractitionerDashboard.tsx` - Analytics dashboard with progress tracking and session insights
- `StudentDashboard.tsx` - Student-specific features with learning analytics
- `PersonaManagement.tsx` - Persona selection and management UI
- `PersonaUploadModal.tsx` - Document upload with AI-powered persona generation

**Backend (Node.js/Express)**
- `index.ts` - Main server orchestrating Express API and WebSocket server
- `llm.ts` - LLM provider router with lazy initialization and error handling
- `routes/auth.ts` - Authentication endpoints with SQLite persistence
- `routes/personas.ts` - Persona CRUD operations with file system integration
- `services/sqlite-auth.ts` - Production-grade authentication with ACID transactions
- `services/persona-generator.ts` - AI-powered persona generation from documents
- `services/document-parser.ts` - Multi-format document parsing (PDF/DOCX)
- `services/ollama-llm.ts` - Local LLM integration with health checks
- `middleware/validation.ts` - Input validation and sanitization
- `middleware/logger.ts` - Structured request/response logging
- `safety.ts` - Crisis detection system with keyword monitoring

---

## ğŸ”„ How It Works

### 1. Authentication & User Management
- **SQLite Database**: Persistent user storage with email indexing
- **Password Hashing**: SHA-256 with secure storage
- **Role-Based Access**: Student and Practitioner dashboards
- **Session Management**: Secure session handling with last login tracking

### 2. Persona System
- **Pre-built Personas**: Sarah Chen (anxiety), Marcus Williams (depression), Elena Rodriguez (PTSD)
- **Custom Persona Generation**: 
  1. Upload therapy case document (PDF/DOCX)
  2. Document parsing and text extraction
  3. AI-powered persona extraction (demographics, concerns, personality)
  4. System prompt and few-shot example generation
  5. JSON storage in knowledge base

### 3. Real-Time Therapy Sessions

**WebSocket Communication Flow:**
```
User Input â†’ WebSocket â†’ Server
  â†“
Crisis Detection (safety.ts)
  â†“
Persona Context Loading (system prompt + few-shot examples)
  â†“
LLM Processing (Gemini API or Ollama HTTP)
  â†“
Response Generation (persona-appropriate reply)
  â†“
WebSocket â†’ Frontend â†’ UI Display + Speech Synthesis
```

**Session Management:**
- Conversation history maintained per WebSocket connection
- Last 20 turns kept in memory for context
- Session reset capability
- Keep-alive pings every 25 seconds

### 4. LLM Provider System

**Dual Provider Architecture:**
- **Provider Abstraction**: Interface-based design allows runtime switching
- **Lazy Initialization**: Only loads selected provider to reduce startup time
- **Graceful Fallback**: Error handling with user-friendly messages
- **Configuration**: Environment variable-based (`LLM_PROVIDER=gemini|ollama`)

**Gemini (Cloud):**
- Google Gemini 2.5 Flash API
- Higher quality responses
- Requires API key
- Best for: Hackathons, demos, production with internet

**Ollama (Local):**
- Llama 3 model running locally
- Complete privacy (no data leaves machine)
- Zero API costs
- Best for: Privacy-focused deployments, offline operation

### 5. Security & Production Features

**Rate Limiting:**
- 100 requests per 15 minutes per IP address
- Prevents DDoS attacks and API abuse
- Configurable limits per endpoint

**Security Headers (Helmet.js):**
- XSS protection
- CSRF protection
- Clickjacking prevention
- Content Security Policy
- HSTS enforcement

**Input Validation:**
- Email format validation
- Password strength requirements (6-128 characters)
- User type validation
- Input sanitization (XSS prevention)
- SQL injection prevention via parameterized queries

**Structured Logging:**
- JSON-formatted logs with timestamps
- Log levels: info, warn, error
- Request/response tracking
- IP address and user agent logging
- Response time metrics

---

## ğŸš€ Quick Start

### Prerequisites
- **Node.js 18+** (20+ recommended)
- **npm** or **yarn**
- **For Gemini**: Google Gemini API key ([Get one here](https://makersuite.google.com/app/apikey))
- **For Ollama**: [Install Ollama](https://ollama.com/download) and pull a model

### Option 1: Using Gemini (Cloud) - Recommended for Demos

```bash
# 1. Backend Setup
cd server
echo "GEMINI_API_KEY=your_api_key_here" > .env
echo "LLM_PROVIDER=gemini" >> .env
npm install
npm start

# 2. Frontend Setup (new terminal)
cd web
echo "NEXT_PUBLIC_WS_URL=ws://localhost:8080" > .env.local
echo "NEXT_PUBLIC_API_URL=http://localhost:3001" >> .env.local
npm install
npm run dev

# 3. Open http://localhost:3000
```

### Option 2: Using Ollama (Local) - Privacy-Focused

```bash
# 1. Install and start Ollama
ollama pull llama3
ollama serve

# 2. Backend Setup
cd server
echo "LLM_PROVIDER=ollama" > .env
echo "OLLAMA_MODEL=llama3" >> .env
echo "OLLAMA_BASE_URL=http://localhost:11434" >> .env
npm install
npm start

# 3. Frontend Setup (new terminal)
cd web
echo "NEXT_PUBLIC_WS_URL=ws://localhost:8080" > .env.local
echo "NEXT_PUBLIC_API_URL=http://localhost:3001" >> .env.local
npm install
npm run dev

# 4. Open http://localhost:3000
```

### Environment Variables

**Backend (`server/.env`):**
```env
# LLM Configuration
LLM_PROVIDER=gemini                    # or "ollama"
GEMINI_API_KEY=your_key_here          # Required for Gemini
OLLAMA_MODEL=llama3                    # Required for Ollama
OLLAMA_BASE_URL=http://localhost:11434 # Required for Ollama

# Server Configuration
PORT=8080                               # WebSocket port
API_PORT=3001                          # REST API port
```

**Frontend (`web/.env.local`):**
```env
NEXT_PUBLIC_WS_URL=ws://localhost:8080
NEXT_PUBLIC_API_URL=http://localhost:3001
```

---

## ğŸ“Š Key Features

### ğŸ¯ Core Functionality
- **Real-Time Therapy Sessions**: WebSocket-based chat with AI personas
- **Multiple AI Personas**: Pre-built and custom personas with unique personalities
- **Document-to-Persona**: Upload therapy cases to generate AI personas automatically
- **Crisis Detection**: Automatic keyword monitoring with safety responses
- **Session Analytics**: Track progress, duration, and interaction patterns

### ğŸ”’ Security & Production
- **SQLite Persistence**: ACID-compliant database with zero data loss
- **Rate Limiting**: DDoS protection with configurable limits
- **Security Headers**: Helmet.js for XSS, CSRF, and clickjacking protection
- **Input Validation**: Comprehensive sanitization and validation
- **Structured Logging**: Production-ready logging with levels and metrics

### ğŸ§  AI & ML
- **Dual LLM Support**: Seamless switching between cloud and local models
- **Persona Generation**: AI-powered extraction from therapy documents
- **Few-Shot Learning**: Context-aware responses with example-based learning
- **Conversation Memory**: Maintains context across 20 conversation turns

### ğŸ¨ User Experience
- **Responsive Design**: Tailwind CSS with mobile-first approach
- **Speech Synthesis**: Browser-based text-to-speech for accessibility
- **Real-Time Updates**: Instant message delivery via WebSocket
- **Error Handling**: User-friendly error messages with graceful degradation

---

## ğŸ† Technical Highlights

### Architecture Decisions

1. **Provider Pattern for LLMs**: Abstracted interface allows adding new LLM providers without code changes
2. **Service Layer Abstraction**: Auth service interface with multiple implementations (SQLite, GCS, In-Memory)
3. **Middleware-Based Validation**: Reusable validation middleware for all endpoints
4. **Session-Based State**: WebSocket sessions maintain conversation history per connection
5. **Graceful Fallbacks**: Multiple fallback chains ensure system reliability

### Performance Optimizations

- **Lazy LLM Initialization**: Only loads selected provider
- **Conversation History Trimming**: Keeps last 20 turns to manage memory
- **Database Indexing**: Email indexes for fast user lookups
- **Connection Pooling**: Efficient WebSocket connection management
- **Rate Limiting**: Prevents resource exhaustion

### Code Quality

- **Full TypeScript Coverage**: Type safety across frontend and backend
- **Modular Architecture**: Separation of concerns with clear interfaces
- **Error Handling**: Comprehensive try-catch blocks with user-friendly messages
- **Code Documentation**: Inline comments and clear function names
- **Environment-Based Config**: Secure configuration management

---

## ğŸ“ Project Structure

```
TherapyAISunHacks/
â”œâ”€â”€ server/                          # Backend server
â”‚   â”œâ”€â”€ index.ts                     # Main server (Express + WebSocket)
â”‚   â”œâ”€â”€ llm.ts                       # LLM provider router
â”‚   â”œâ”€â”€ safety.ts                    # Crisis detection system
â”‚   â”œâ”€â”€ database/                    # SQLite database files
â”‚   â”‚   â””â”€â”€ users.db                 # User data (gitignored)
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ auth.ts                  # Authentication endpoints
â”‚   â”‚   â””â”€â”€ personas.ts              # Persona CRUD operations
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ sqlite-auth.ts          # Production auth service
â”‚   â”‚   â”œâ”€â”€ fallback-auth.ts         # In-memory fallback
â”‚   â”‚   â”œâ”€â”€ gcs-service.ts          # Google Cloud Storage auth
â”‚   â”‚   â”œâ”€â”€ persona-generator.ts    # AI persona generation
â”‚   â”‚   â”œâ”€â”€ document-parser.ts      # PDF/DOCX parsing
â”‚   â”‚   â”œâ”€â”€ ollama-llm.ts           # Ollama integration
â”‚   â”‚   â””â”€â”€ auth-interface.ts       # Auth service interface
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”œâ”€â”€ validation.ts           # Input validation
â”‚   â”‚   â””â”€â”€ logger.ts                # Structured logging
â”‚   â”œâ”€â”€ knowledge-base/
â”‚   â”‚   â”œâ”€â”€ personas/                # Default personas
â”‚   â”‚   â”œâ”€â”€ custom-personas/         # User-generated personas
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â””â”€â”€ persona-loader.ts    # Persona loading logic
â”‚   â””â”€â”€ package.json                 # Dependencies
â”‚
â”œâ”€â”€ web/                              # Frontend application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ page.tsx                 # Landing page
â”‚   â”‚   â”œâ”€â”€ layout.tsx               # Root layout
â”‚   â”‚   â””â”€â”€ globals.css              # Global styles
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ TherapyAi.tsx           # Main therapy interface
â”‚   â”‚   â”œâ”€â”€ PractitionerDashboard.tsx
â”‚   â”‚   â”œâ”€â”€ StudentDashboard.tsx
â”‚   â”‚   â”œâ”€â”€ PersonaManagement.tsx
â”‚   â”‚   â””â”€â”€ PersonaUploadModal.tsx
â”‚   â””â”€â”€ package.json                 # Dependencies
â”‚
â”œâ”€â”€ docker-compose.yml                # Docker orchestration
â”œâ”€â”€ Dockerfile                        # Docker image
â”œâ”€â”€ vercel.json                      # Vercel deployment
â””â”€â”€ README.md                        # This file
```

---

## ğŸ”§ Customization

### Switching LLM Providers

```bash
# Use Ollama
export LLM_PROVIDER=ollama
export OLLAMA_MODEL=llama3

# Use Gemini
export LLM_PROVIDER=gemini
export GEMINI_API_KEY=your_key
```

### Adjusting LLM Parameters

**Ollama** (`server/services/ollama-llm.ts`):
- `temperature`: 0.3-0.8 (creativity)
- `num_predict`: 200-500 (response length)
- `repeat_penalty`: 1.0-1.2 (repetition control)

**Gemini** (`server/llm.ts`):
- `temperature`: 0.7-0.9 (creativity)
- `maxOutputTokens`: 512-2048 (response length)

---

## ğŸ› Troubleshooting

**Connection Issues:**
- Verify WebSocket URL in `web/.env.local`
- Check backend is running on correct ports
- Ensure firewall allows connections

**LLM Errors:**
- **Gemini**: Verify API key is valid and has quota
- **Ollama**: Ensure service is running (`ollama serve`)
- Check model is installed (`ollama list`)

**Database Issues:**
- SQLite database auto-creates on first run
- Check file permissions in `server/database/`
- Verify database directory exists

---

## âš ï¸ Safety & Disclaimer

**This is an educational tool for training purposes only.**

- âŒ **NOT** a substitute for professional mental health services
- âŒ **NOT** a crisis intervention tool
- âœ… **IS** a training platform for students and practitioners

If someone is in immediate danger, contact local emergency services immediately.

---

## ğŸ“ License

This project is open source and available for educational purposes.

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---

## ğŸ“§ Contact

For questions or feedback, please open an issue on GitHub.

---

**Built with â¤ï¸ using Next.js, Express, TypeScript, and modern AI technologies.**
